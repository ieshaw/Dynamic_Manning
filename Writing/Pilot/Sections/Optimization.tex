Alternate to deterministic algorithms (such as Deferred Acceptance \cite{1962_Gale}) is a linear programming (optimization) approach. This allows system owners to input strategic objectives in the seeker-owner job matching process. The importance of job seeker preference can be weighted to be more important than owner, or vice versa. Requirements can also be added, as you will see in the formulation below.

The optimization function takes the form:

\begin{align}
\min \qquad & \sum_{i = 1}^{n} \sum_{j = 1}^{m} f(X_{ij}) \label{obj_func}\\
\text{ such that } \qquad & \sum_{j=1}^m X_{i,j} \leq 1 \quad  \forall i \in \{1, \dots n\} \label{one_job}\\
& \sum_{i = 1}^{i=n} \sum_{j = 1}^{m}X_{ij} = \min \left(n,\sum_{j = 1}^{m}a_j \right) \quad  \forall j \in \{1, \dots m\}  \label{all_filled}\\
& \sum_{i=1}^n X_{ij} \leq a_j \quad  \forall j \in \{1, \dots m\} \label{capacity} \\
\end{align}

The Goodness Function $f$ is the strategic objective function of the assignment process. For the sake of this paper, we set it to value the preference of the seeker twice as much as the preference of th job owner.

\[f(X_{ij}) = X_{ij}(P^S_{ij} + P^O_{ji})\]

In matrix form this can be re-written (with $tr()$ indicating the trace):

\begin{align}
\min \qquad & tr(XP^O) + tr(X^TP^S) \label{mat_obj_func} \\
\text{ such that } \qquad & X^T \times 1^{m \times 1}  \leq 1  \label{one_job_matrix}\\
& (X \bullet 1)\bullet 1 = \min(n,A \bullet 1^{m \times 1}) \label{all_filled_matrix}\\
& X \times 1^{n \times 1} \leq A \label{capacity_matrix} \\
\end{align}

The proof for the equivalence of the objective functions (\ref{obj_func}) and (\ref{mat_obj_func}) is in Section \ref{mat_obj_func_proof}. The constraints in lines (\ref{one_job}) and (\ref{one_job_matrix}) ensure that each seeker receives only one job, lines (\ref{all_filled}) and (\ref{all_filled_matrix}) ensure that either all the jobs are filled or everyone has a job, and lines (\ref{capacity}) and (\ref{capacity_matrix}) ensures that all jobs are at or below capacity (do not exceed capacity).

\subsection{Matrix formulation of Objective Function}
\label{mat_obj_func_proof}

\begin{align}
\sum_{i = 1}^{n} \sum_{j = 1}^{m} f(X_{ij}) &= \sum_{i = 1}^{n} \sum_{j = 1}^{m} X_{ji}\left(P^S_{ji} + P^O_{ij}\right)\\
&=   \sum_{j = 1}^{m}\sum_{i = 1}^{n} X_{ji}\left(\left(P^S\right)^T_{ij} + P^O_{ij}\right)\\
&=   \sum_{j = 1}^{m}\sum_{i = 1}^{n} X_{ji}\left(\left(P^S\right)^T + P^O\right)_{ij}\\
&=   \sum_{j = 1}^{m} \left( X\left(\left(P^S\right)^T + P^O \right)\right)_{jj}\\
&=   tr\left( X\left(\left(P^S\right)^T + P^O \right)\right)\\
%&= \sum_{i = 1}^{n} \sum_{j = 1}^{m} X_{ji}P^S_{ji} + \sum_{i = 1}^{n} \sum_{j = 1}^{m} X_{ji}P^O_{ij} \\
%&=  \sum_{i = 1}^{n} \sum_{j = 1}^{m} X^T_{ij}P^S_{ji} + \sum_{j = 1}^{m} \sum_{i = 1}^{n} X_{ji}P^O_{ij} \label{pre_jump}\\
%&= \sum_{i = 1}^{n} (X^TP^S)_{ii} + \sum_{j = 1}^{m}(XP^O)_{jj} \label{post_jump}\\
%&= tr(X^TP^S) + tr(XP^O)
\end{align}
